Tools for Kubernetes
1.  Best ways for Canary Deployments --> Istio (Open Source) and AWS AppMesh (AWS version of Istio)

eksctl create cluster --name=eksdemo1 \
                      --region=ap-southeast-1 \
                      --zones=ap-southeast-1a,ap-southeast-1b \
                      --without-nodegroup 

eksctl create cluster --name=eksdemo1 --region=ap-southeast-1 --zones=ap-southeast-1a,ap-southeast-1b --without-nodegroup
publicAccess=true, privateAccess=false

# Create Public Node Group   
eksctl create nodegroup --cluster=eksdemo1 \
                       --region=ap-southeast-1 \
                       --name=eksdemo1-ng-public1 \
                       --node-type=t3.small \
                       --nodes=1 \
                       --nodes-min=1 \
                       --nodes-max=2 \
                       --node-volume-size=20 \
                       --ssh-access \
                       --ssh-public-key=kube-demo \
                       --managed \
                       --asg-access \
                       --external-dns-access \
                       --full-ecr-access \
                       --appmesh-access \
                       --alb-ingress-access 

eksctl create nodegroup --cluster=eksdemo1 --region=ap-southeast-1 --name=eksdemo1-ng-public1 --node-type=t3.small --nodes=2 --nodes-min=2 --nodes-max=3 --node-volume-size=20 --ssh-access --ssh-public-key=kube-demo --managed --asg-access --external-dns-access --full-ecr-access --appmesh-access --alb-ingress-access

eksctl utils associate-iam-oidc-provider \
    --region ap-southeast-1 \
    --cluster eksdemo1 \
    --approve

eksctl utils associate-iam-oidc-provider --region ap-southeast-1 --cluster eksdemo1 --approve

# Create EKS NodeGroup in VPC Private Subnets (Section-07-01)
eksctl create nodegroup --cluster=eksdemo1 \
                        --region=ap-southeast-1 \
                        --name=eksdemo1-ng-private1 \
                        --node-type=t3.small \
                        --nodes-min=1 \
                        --nodes-max=3 \
                        --node-volume-size=20 \
                        --ssh-access \
                        --ssh-public-key=kube-demo \
                        --managed \
                        --asg-access \
                        --external-dns-access \
                        --full-ecr-access \
                        --appmesh-access \
                        --alb-ingress-access \
                        --node-private-networking     
						
eksctl create nodegroup --cluster=eksdemo1 --region=ap-southeast-1 --name=eksdemo1-ng-private1 --node-type=t3.small --nodes-min=1 --nodes-max=3 --node-volume-size=20 --ssh-access --ssh-public-key=kube-demo --managed --asg-access --external-dns-access --full-ecr-access --appmesh-access --alb-ingress-access --node-private-networking
						
eksctl scale nodegroup --cluster=eksdemo1 --nodes=2 --name=eksdemo1-ng-private1

eksctl create fargateprofile --cluster eksdemo1 \
                             --name fp-demo \
                             --namespace fp-dev

eksctl create fargateprofile --cluster eksdemo1 --name fp-demo --namespace fp-dev

eksctl delete nodegroup --name=eksdemo1-ng-public1 --cluster=eksdemo1
eksctl delete nodegroup --name=eksdemo1-ng-private1 --cluster=eksdemo1

eksctl delete cluster --name=eksdemo1

to remove ssh open key permission

icacls .\kube-demo.pem /inheritance:r
icacls.exe .\kube-demo.pem /GRANT:R "$($env:USERNAME):(R)"


-----------------------------

1.  Create cluster and Nodegroup
2.  Amazon_EBS_CSI_Driver --> Add policy to newly created roles in IAM
3. Install CSI driver using command --> kubectl apply -k "github.com/kubernetes-sigs/aws-ebs-csi-driver/deploy/kubernetes/overlays/stable/?ref=master"
    # Verify ebs-csi pods running
    kubectl get pods -n kube-system	
4. optional(latest policy for aws-load-balancer-controller ---> curl -o iam_policy_latest.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/main/docs/install/iam_policy.json
5.create service account in kubectl
6.	Helm install aws-load-balancer-controller  (https://docs.aws.amazon.com/eks/latest/userguide/add-ons-images.html --> for more information)
7. Review IngressClass Kubernetes Manifest and run for aws loadbalancer
8. create external-dns iamserviceaccount
9. deploy external dns manifest (https://github.com/kubernetes-sigs/external-dns/releases/tag/v0.10.2 --> for more info)


while deleting cluster
kubectl delete -k "github.com/kubernetes-sigs/aws-ebs-csi-driver/deploy/kubernetes/overlays/stable/?ref=master"
kubectl get pdb -A
kubectl delete pdb ebs-csi-controller -n kube-system
kubectl delete events --all
helm uninstall aws-load-balancer-controller -n kube-system 


kubectl run -it --rm --image=mysql:8.0.33 --restart=Never mysql-client -- mysql -h usermgmtdb.c447fu2ivttg.ap-southeast-1.rds.amazonaws.com   -u dbadmin -pdbpassword11


create service account in kubectl
#Note:  K8S Service Account Name that need to be bound to newly created IAM Role
eksctl create iamserviceaccount \
  --cluster=eksdemo1 \
  --namespace=kube-system \
  --name=aws-load-balancer-controller \ 
  --attach-policy-arn=arn:aws:iam::701162217244:policy/AWSLoadBalancerControllerIAMPolicy \
  --override-existing-serviceaccounts \
  --approve
 
 
eksctl create iamserviceaccount --cluster=eksdemo1 --namespace=kube-system --name=aws-load-balancer-controller --attach-policy-arn=arn:aws:iam::701162217244:policy/AWSLoadBalancerControllerIAMPolicy --override-existing-serviceaccounts --approve
eksctl delete iamserviceaccount --cluster=eksdemo1 --namespace=kube-system --name=aws-load-balancer-controller
  
  eksctl create iamserviceaccount --cluster=eksdemo1 --namespace=kube-system --name=aws-load-balancer-controller --attach-policy-arn=arn:aws:iam::701162217244:policy/AWSLoadBalancerControllerIAMPolicy --override-existing-serviceaccounts --approve
  eksctl delete iamserviceaccount --cluster=eksdemo1 --namespace=kube-system --name=aws-load-balancer-controller
  
  
  eksctl utils associate-iam-oidc-provider \
    --region ap-southeast-1 \
    --cluster eksdemo1 \
    --approve
	
	
# Install the AWS Load Balancer Controller.
	

 
## Template
helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
  -n kube-system \
  --set clusterName=<cluster-name> \
  --set serviceAccount.create=false \
  --set serviceAccount.name=aws-load-balancer-controller \
  --set region=<region-code> \
  --set vpcId=<vpc-xxxxxxxx> \
  --set image.repository=<account>.dkr.ecr.<region-code>.amazonaws.com/amazon/aws-load-balancer-controller

## Replace Cluster Name, Region Code, VPC ID, Image Repo Account ID and Region Code  
helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
  -n kube-system \
  --set clusterName=eksdemo1 \
  --set serviceAccount.create=false \
  --set serviceAccount.name=aws-load-balancer-controller \
  --set region=ap-southeast-1 \
  --set vpcId=vpc-0617555937d07cc7e \
  --set image.repository=602401143452.dkr.ecr.ap-southeast-1.amazonaws.com/amazon/aws-load-balancer-controller

helm install aws-load-balancer-controller eks/aws-load-balancer-controller -n kube-system --set clusterName=eksdemo1 --set serviceAccount.create=false --set region=ap-southeast-1 --set vpcId=vpc-054c89310c9ce16df --set image.repository=602401143452.dkr.ecr.ap-southeast-1.amazonaws.com/amazon/aws-load-balancer-controller
helm uninstall aws-load-balancer-controller -n kube-system 

eksctl create iamserviceaccount \
    --name external-dns \
    --namespace default \
    --cluster eksdemo1 \
    --attach-policy-arn arn:aws:iam::701162217244:policy/AllowExternalDNSUpdates \
    --approve \
    --override-existing-serviceaccounts
	
aws ecr create-repository --repository-name aws-ecr-kubenginx --region ap-southeast-1
	
	
eksctl create iamserviceaccount --name external-dns --namespace default --cluster eksdemo1 --attach-policy-arn arn:aws:iam::701162217244:policy/AllowExternalDNSUpdates --approve --override-existing-serviceaccounts
eksctl delete iamserviceaccount --name external-dns --namespace default --cluster eksdemo1

aws eks --region ap-southeast-1 update-kubeconfig --name eksdemo1

clearing all

delete ingress ingressclass resource

ACM : arn:aws:acm:ap-southeast-1:701162217244:certificate/a8f40e8b-2c5c-4df3-b396-79fc61479c8e